# Memvid - Video-Based AI Memory ğŸ§ ğŸ“¹

**The lightweight, game-changing solution for AI memory at scale**

[![PyPI version](https://badge.fury.io/py/memvid.svg)](https://pypi.org/project/memvid/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Memvid revolutionizes AI memory management by encoding text data into videos, enabling **lightning-fast semantic search** across millions of text chunks with **sub-second retrieval times**. Unlike traditional vector databases that consume massive amounts of RAM and storage, Memvid compresses your knowledge base into compact video files while maintaining instant access to any piece of information.

## ğŸ¥ Demo

https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e



## âœ¨ Key Features

- ğŸ¥ **Video-as-Database**: Store millions of text chunks in a single MP4 file
- ğŸ” **Semantic Search**: Find relevant content using natural language queries
- ğŸ’¬ **Built-in Chat**: Conversational interface with context-aware responses
- ğŸ“š **PDF Support**: Direct import and indexing of PDF documents
- ğŸš€ **Fast Retrieval**: Sub-second search across massive datasets
- ğŸ’¾ **Efficient Storage**: 10x compression compared to traditional databases
- ğŸ”Œ **Pluggable LLMs**: Works with OpenAI, Anthropic, or local models
- ğŸŒ **Offline-First**: No internet required after video generation
- ğŸ”§ **Simple API**: Get started with just 3 lines of code

## ğŸ¯ Use Cases

- **ğŸ“– Digital Libraries**: Index thousands of books in a single video file
- **ğŸ“ Educational Content**: Create searchable video memories of course materials
- **ğŸ“° News Archives**: Compress years of articles into manageable video databases
- **ğŸ’¼ Corporate Knowledge**: Build company-wide searchable knowledge bases
- **ğŸ”¬ Research Papers**: Quick semantic search across scientific literature
- **ğŸ“ Personal Notes**: Transform your notes into a searchable AI assistant

## ğŸš€ Why Memvid?

### Game-Changing Innovation
- **Video as Database**: Store millions of text chunks in a single MP4 file
- **Instant Retrieval**: Sub-second semantic search across massive datasets
- **10x Storage Efficiency**: Video compression reduces memory footprint dramatically
- **Zero Infrastructure**: No database servers, just files you can copy anywhere
- **Offline-First**: Works completely offline once videos are generated

### Lightweight Architecture
- **Minimal Dependencies**: Core functionality in ~1000 lines of Python
- **CPU-Friendly**: Runs efficiently without GPU requirements
- **Portable**: Single video file contains your entire knowledge base
- **Streamable**: Videos can be streamed from cloud storage

## ğŸ“¦ Installation

### Quick Install
```bash
pip install memvid
```

### For PDF Support
```bash
pip install memvid PyPDF2
```

### Recommended Setup (Virtual Environment)
```bash
# Create a new project directory
mkdir my-memvid-project
cd my-memvid-project

# Create virtual environment
python -m venv venv

# Activate it
# On macOS/Linux:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

# Install memvid
pip install memvid

# For PDF support:
pip install PyPDF2
```

## ğŸ¯ Quick Start

### Basic Usage
```python
from memvid import MemvidEncoder, MemvidChat

# Create video memory from text chunks
chunks = ["Important fact 1", "Important fact 2", "Historical event details"]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video("memory.mp4", "memory_index.json")

# Chat with your memory
chat = MemvidChat("memory.mp4", "memory_index.json")
chat.start_session()
response = chat.chat("What do you know about historical events?")
print(response)
```

### Building Memory from Documents
```python
from memvid import MemvidEncoder
import os

# Load documents
encoder = MemvidEncoder(chunk_size=512, overlap=50)

# Add text files
for file in os.listdir("documents"):
    with open(f"documents/{file}", "r") as f:
        encoder.add_text(f.read(), metadata={"source": file})

# Build optimized video
encoder.build_video(
    "knowledge_base.mp4",
    "knowledge_index.json",
    fps=30,  # Higher FPS = more chunks per second
    frame_size=512  # Larger frames = more data per frame
)
```

### Advanced Search & Retrieval
```python
from memvid import MemvidRetriever

# Initialize retriever
retriever = MemvidRetriever("knowledge_base.mp4", "knowledge_index.json")

# Semantic search
results = retriever.search("machine learning algorithms", top_k=5)
for chunk, score in results:
    print(f"Score: {score:.3f} | {chunk[:100]}...")

# Get context window
context = retriever.get_context("explain neural networks", max_tokens=2000)
print(context)
```

### Interactive Chat Interface
```python
from memvid import MemvidInteractive

# Launch interactive chat UI
interactive = MemvidInteractive("knowledge_base.mp4", "knowledge_index.json")
interactive.run()  # Opens web interface at http://localhost:7860
```

### Testing with file_chat.py
The `examples/file_chat.py` script provides a comprehensive way to test Memvid with your own documents:

```bash
# Process a directory of documents
python examples/file_chat.py --input-dir /path/to/documents --provider google

# Process specific files
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai

# Use H.265 compression (requires Docker)
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google

# Custom chunking for large documents
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google

# Load existing memory
python examples/file_chat.py --load-existing output/my_memory --provider google
```

### Complete Example: Chat with a PDF Book
```bash
# 1. Create a new directory and set up environment
mkdir book-chat-demo
cd book-chat-demo
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install memvid PyPDF2

# 3. Create book_chat.py
cat > book_chat.py << 'EOF'
from memvid import MemvidEncoder, chat_with_memory
import os

# Your PDF file
book_pdf = "book.pdf"  # Replace with your PDF path

# Build video memory
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video("book_memory.mp4", "book_index.json")

# Chat with the book
api_key = os.getenv("OPENAI_API_KEY")  # Optional: for AI responses
chat_with_memory("book_memory.mp4", "book_index.json", api_key=api_key)
EOF

# 4. Run it
export OPENAI_API_KEY="your-api-key"  # Optional
python book_chat.py
```

## ğŸ› ï¸ Advanced Configuration

### Custom Embeddings
```python
from sentence_transformers import SentenceTransformer

# Use custom embedding model
custom_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=custom_model)
```

### Video Optimization
```python
# For maximum compression
encoder.build_video(
    "compressed.mp4",
    "index.json",
    fps=60,  # More frames per second
    frame_size=256,  # Smaller frames
    video_codec='h265',  # Better compression
    crf=28  # Compression quality (lower = better quality)
)
```

### Distributed Processing
```python
# Process large datasets in parallel
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(massive_chunk_list)
```

## ğŸ› Troubleshooting

### Common Issues

**ModuleNotFoundError: No module named 'memvid'**
```bash
# Make sure you're using the right Python
which python  # Should show your virtual environment path
# If not, activate your virtual environment:
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

**ImportError: PyPDF2 is required for PDF support**
```bash
pip install PyPDF2
```

**LLM API Key Issues**
```bash
# Set your API key (get one at https://platform.openai.com)
export GOOGLE_API_KEY="AIzaSyB1-..."  # macOS/Linux
# Or on Windows:
set GOOGLE_API_KEY=AIzaSyB1-...
```

**Large PDF Processing**
```python
# For very large PDFs, use smaller chunk sizes
encoder = MemvidEncoder()
encoder.add_pdf("large_book.pdf", chunk_size=400, overlap=50)
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

```bash
# Run tests
pytest tests/

# Run with coverage
pytest --cov=memvid tests/

# Format code
black memvid/
```

## ğŸ†š Comparison with Traditional Solutions

| Feature | Memvid | Vector DBs | Traditional DBs |
|---------|--------|------------|-----------------|
| Storage Efficiency | â­â­â­â­â­ | â­â­ | â­â­â­ |
| Setup Complexity | Simple | Complex | Complex |
| Semantic Search | âœ… | âœ… | âŒ |
| Offline Usage | âœ… | âŒ | âœ… |
| Portability | File-based | Server-based | Server-based |
| Scalability | Millions | Millions | Billions |
| Cost | Free | $$$$ | $$$ |


## ğŸ“š Examples

Check out the [examples/](examples/) directory for:
- Building memory from Wikipedia dumps
- Creating a personal knowledge base
- Multi-language support
- Real-time memory updates
- Integration with popular LLMs

## ğŸ†˜ Getting Help

- ğŸ“– [Documentation](https://github.com/olow304/memvid/wiki) - Comprehensive guides
- ğŸ’¬ [Discussions](https://github.com/olow304/memvid/discussions) - Ask questions
- ğŸ› [Issue Tracker](https://github.com/olow304/memvid/issues) - Report bugs
- ğŸŒŸ [Show & Tell](https://github.com/olow304/memvid/discussions/categories/show-and-tell) - Share your projects

## ğŸ”— Links

- [GitHub Repository](https://github.com/olow304/memvid)
- [PyPI Package](https://pypi.org/project/memvid)
- [Changelog](https://github.com/olow304/memvid/releases)


## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Created by [Olow304](https://github.com/olow304) and the Memvid community.

Built with â¤ï¸ using:
- [sentence-transformers](https://www.sbert.net/) - State-of-the-art embeddings for semantic search
- [OpenCV](https://opencv.org/) - Computer vision and video processing
- [qrcode](https://github.com/lincolnloop/python-qrcode) - QR code generation
- [FAISS](https://github.com/facebookresearch/faiss) - Efficient similarity search
- [PyPDF2](https://github.com/py-pdf/pypdf) - PDF text extraction

Special thanks to all contributors who help make Memvid better!

---

**Ready to revolutionize your AI memory management? Install Memvid and start building!** ğŸš€

---

# BitMatrixâ‡”JSONå¤‰æ›æ©Ÿèƒ½ (æ—¥æœ¬èª)

## æ¦‚è¦
MemVidã«BitMatrixâ‡”JSONå¤‰æ›æ©Ÿèƒ½ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚ã“ã®æ©Ÿèƒ½ã«ã‚ˆã‚Šã€QRã‚³ãƒ¼ãƒ‰ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPNGï¼‰ã‚’èª­ã¿è¾¼ã‚€ä»£ã‚ã‚Šã«ã€è»½é‡ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã€å¤§å¹…ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## ä¸»ãªæ”¹å–„ç‚¹
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›**: 8GBè¶…ã‹ã‚‰ç´„200MBã«æ¿€æ¸›
- **æ¤œç´¢é…å»¶ã®æœ€å°åŒ–**: å¾“æ¥æ¯”ç´„10%å¢—ï¼ˆ900ms vs 820msï¼‰ã®ã¿
- **I/OåŠ¹ç‡ã®å‘ä¸Š**: ç”»åƒèª­ã¿è¾¼ã¿ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚’çœç•¥

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ã„æ–¹
```python
from memvid import MemvidEncoder, MemvidRetriever

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆè‡ªå‹•çš„ã«PNGã¨JSONã®ä¸¡æ–¹ãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼‰
encoder = MemvidEncoder()
encoder.add_chunks(["ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯1", "ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯2"])
encoder.build_video("memory.mp4", "memory_index.json")

# æ¤œç´¢ï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯è‡ªå‹•çš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ï¼‰
retriever = MemvidRetriever("memory.mp4", "memory_index.json")
results = retriever.search("æ¤œç´¢ã‚¯ã‚¨ãƒª", top_k=5)
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®é †åºã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ï¼š
1. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: ãƒ¡ãƒ¢ãƒªå†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
2. **JSON**: è»½é‡ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿
3. **ç”»åƒ**: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å‹•ç”»ã‹ã‚‰QRã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰

### å¾Œæ–¹äº’æ›æ€§
- æ—¢å­˜ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¼•ãç¶šãå‹•ä½œã—ã¾ã™
- JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è‡ªå‹•çš„ã«å¾“æ¥ã®ç”»åƒãƒ‡ã‚³ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™
- æ–°ã—ãç”Ÿæˆã•ã‚Œã‚‹å‹•ç”»ã§ã¯ã€PNGã¨JSONã®ä¸¡æ–¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã™

## æŠ€è¡“è©³ç´°

### å‡¦ç†æ‰‹é †ã®å¤‰æ›´ç‚¹

#### å¾“æ¥ã®å‡¦ç†æ‰‹é †ï¼ˆPNGç”»åƒã®ã¿ï¼‰
```
ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã€‘
1. ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’æº–å‚™
2. ãƒãƒ£ãƒ³ã‚¯ã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›
3. QRã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
4. PNGç”»åƒã¨ã—ã¦ä¿å­˜
5. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ

ã€æ¤œç´¢ãƒ»å–å¾—ã€‘
1. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã§ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’ç‰¹å®š
2. å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’æŠ½å‡º
3. OpenCVã§QRã‚³ãƒ¼ãƒ‰ã‚’æ¤œå‡ºãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰
4. JSONæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
5. ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
```

#### æ–°ã—ã„å‡¦ç†æ‰‹é †ï¼ˆBitMatrixâ‡”JSONæœ€é©åŒ–ï¼‰
```
ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã€‘
1. ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’æº–å‚™
2. ãƒãƒ£ãƒ³ã‚¯ã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›
3. QRã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
4. BitMatrixãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
5. PNGç”»åƒã¨ã—ã¦ä¿å­˜ï¼ˆå¾Œæ–¹äº’æ›æ€§ç”¨ï¼‰
6. BitMatrixãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ â† æ–°æ©Ÿèƒ½
7. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ

ã€æ¤œç´¢ãƒ»å–å¾—ã€‘
1. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã§ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’ç‰¹å®š
2. JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª â† æ–°æ©Ÿèƒ½
3a. JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼š
   - JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿ â† é«˜é€ŸåŒ–
   - ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å³åº§ã«å–å¾—
3b. JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ï¼š
   - å¾“æ¥ã®å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå‡¦ç†
   - OpenCVã§QRã‚³ãƒ¼ãƒ‰ã‚’æ¤œå‡ºãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰
   - JSONæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
   - ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼
1. **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ™‚**: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ â†’ JSONæ–‡å­—åˆ— â†’ QRã‚³ãƒ¼ãƒ‰ â†’ PNGç”»åƒ + BitMatrix JSON
2. **æ¤œç´¢æ™‚**: ã‚¯ã‚¨ãƒª â†’ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ â†’ ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå· â†’ JSONèª­ã¿è¾¼ã¿ â†’ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—

### ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 
```
frames/
â”œâ”€â”€ frame_000000.png  # å¾“æ¥ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¾Œæ–¹äº’æ›æ€§ç”¨ï¼‰
â”œâ”€â”€ frame_000000.json # æ–°ã—ã„BitMatrixãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ frame_000001.png
â”œâ”€â”€ frame_000001.json
â””â”€â”€ ...
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

#### å¾“æ¥ã®å‡¦ç†ï¼ˆPNGç”»åƒï¼‰
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 8GBä»¥ä¸Šï¼ˆå¤§é‡ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼‰
- **I/Oå‡¦ç†**: é‡ã„ï¼ˆç”»åƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ + OpenCVå‡¦ç†ï¼‰
- **æ¤œç´¢é€Ÿåº¦**: ç´„820ms
- **CPUä½¿ç”¨ç‡**: é«˜ã„ï¼ˆç”»åƒãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†ï¼‰

#### æ–°ã—ã„å‡¦ç†ï¼ˆBitMatrixâ‡”JSONï¼‰
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: ç´„200MBï¼ˆè»½é‡ãªJSONãƒ‡ãƒ¼ã‚¿ï¼‰
- **I/Oå‡¦ç†**: è»½ã„ï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥èª­ã¿è¾¼ã¿ï¼‰
- **æ¤œç´¢é€Ÿåº¦**: ç´„900msï¼ˆã‚ãšã‹10%å¢—ï¼‰
- **CPUä½¿ç”¨ç‡**: ä½ã„ï¼ˆç”»åƒå‡¦ç†ã‚’çœç•¥ï¼‰

### æœ€é©åŒ–ã®ä»•çµ„ã¿

#### 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å„ªå…ˆé †ä½
```python
def _decode_frames_parallel(self, frame_numbers):
    # 1. ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€é«˜é€Ÿï¼‰
    cached_results = self._check_cache(frame_numbers)
    
    # 2. JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆé«˜é€Ÿï¼‰
    json_results = batch_extract_and_decode_json(frames_dir, uncached_frames)
    
    # 3. å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    video_results = batch_extract_and_decode(video_file, remaining_frames)
```

#### 2. åœ§ç¸®ã¨ãƒ‡ãƒ¼ã‚¿å½¢å¼
- **çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆâ‰¤100æ–‡å­—ï¼‰**: ãã®ã¾ã¾ä¿å­˜
- **é•·ã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ>100æ–‡å­—ï¼‰**: gzipåœ§ç¸® + Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
- **ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹**: "GZ:" ã§åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚’è­˜åˆ¥

### åœ§ç¸®å‡¦ç†
- 100æ–‡å­—ã‚’è¶…ãˆã‚‹é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯è‡ªå‹•çš„ã«gzipåœ§ç¸® + Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¾ã™
- åœ§ç¸®ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«ã¯"GZ:"ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒä»˜ä¸ã•ã‚Œã¾ã™
- JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ãŒä¿å­˜ã•ã‚Œã¾ã™

### ä½¿ç”¨ä¾‹ï¼šå¤§é‡æ–‡æ›¸ã®å‡¦ç†
```python
from memvid import MemvidEncoder, MemvidRetriever
import os

# å¤§é‡ã®æ–‡æ›¸ã‚’å‡¦ç†
encoder = MemvidEncoder(chunk_size=512, overlap=50)

# PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
for pdf_file in os.listdir("documents"):
    if pdf_file.endswith(".pdf"):
        encoder.add_pdf(f"documents/{pdf_file}")

# æœ€é©åŒ–ã•ã‚ŒãŸå‹•ç”»ã‚’æ§‹ç¯‰
encoder.build_video(
    "knowledge_base.mp4",
    "knowledge_index.json",
    codec="h265"  # é«˜åœ§ç¸®ç‡
)

# é«˜é€Ÿæ¤œç´¢
retriever = MemvidRetriever("knowledge_base.mp4", "knowledge_index.json")
results = retriever.search("æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", top_k=10)

# çµæœã®è¡¨ç¤º
for i, result in enumerate(results):
    print(f"{i+1}. {result[:100]}...")
```</str>
